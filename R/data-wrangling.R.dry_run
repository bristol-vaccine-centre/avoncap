# Import AVONCAP data and cleanse into a tidy data format
# assuming there will be changes to the format we would like to be able to make
# the import reverse compatible to previous versions of the data.

#' Locate the input directory
#'
#' @param path the sub path(s) within the input directory
#'
#' @return a path to the input directory and sub path(s) if provided
#' @export
#'
#' @examples
#' opt = options("avoncap.input"=tempdir())
#' # options("avoncap.input" = "~/Git/avoncap-analysis/input")
#' input()
#' options(opt)
input = function(path = "") {
  dir = getOption("avoncap.input")
  if(is.null(dir)) stop("The data input directory must be defined by setting option('avoncap.input'='~/path/to/input')")
  dir = normalizePath(dir)
  if (!fs::dir_exists(dir)) stop ("The input directory must exist: ",dir)
  return(fs::path(dir,path))
}

# Read in secrets file from input directory.
.secrets = function(path = input("avoncap.yaml")) {
  out = yaml::read_yaml(path)
  return(out)
}

## File handling functions ----

#' Scans the input directory and returns csv or xlsx files in that directory
#'
#' Extracting metadata from the filename where present - particularly hospital, and year number
#'
#' @return a dataframe containing filename, path, date, hospital, and study_year fields
#' @export
#'
#' @examples
#' all_files()
all_files = function() {
  files = fs::dir_ls(input(),recurse = TRUE) %>% stringr::str_subset(".+\\.(csv)")
  info = fs::file_info(files) %>% dplyr::mutate(
    filename = path %>% fs::path_ext_remove() %>% fs::path_file() %>% stringr::str_extract("[a-zA-Z\\s]+") %>% trimws(),
    directory = path %>% fs::path_rel(input()) %>% fs::path_split() %>% purrr::map(~ .[[1]]) %>% unlist()
  )
  info %>%
    dplyr::mutate(
      modification_date = as.Date(modification_time),
      filename_date = path %>% fs::path_file() %>% fs::path_ext_remove() %>% stringr::str_extract("\\d+") %>% stringr::str_replace("^(\\d{4})(\\d{2})$","\\120\\2") %>% as.Date(format="%d%m%Y"),
      filetype = fs::path_ext(path),
      hospital = dplyr::case_when(
        stringr::str_detect(path,"NBT") ~ "NBT",
        stringr::str_detect(path,"BRI") ~ "BRI",
        TRUE ~ NA_character_
      ),
      study_year = (path %>% fs::path_file() %>% fs::path_ext_remove() %>% stringr::str_match("_y([1-9])"))[,2],
      study_year2 = (path %>% fs::path_file() %>% fs::path_ext_remove() %>% stringr::str_match("2[0-9]-2([0-9])"))[,2],
      date = pmin(modification_date,filename_date,na.rm = TRUE),
      study_year = ifelse(is.na(study_year) & !is.na(study_year2), study_year2, study_year)
    ) %>%
    dplyr::select(filename, directory, path, date, hospital, study_year, filetype)
}


#' find most recent files of a specific type
#'
#' @param type - see valid_types() for current list of supported types in input directory
#' @param reproduce_at after this date new files are ignored. This enforces a specific version of the data.
#'
#' @return a list of the file paths to the most up to date files of the given type relevant to each site and study year
#' @export
#'
#' @examples
#' # exact match on filename column of all_data()
#' most_recent_files("AvonCAPLRTDCentralDa")
#' # or matches by lower case startWith on directory
#' most_recent_files("nhs-extract")
most_recent_files = function(type, reproduce_at = as.Date(getOption("reproduce.at",default = Sys.Date()))) {
  all_files() %>%
    stats::filter(
      (startsWith(tolower(directory), tolower(type))
        | filename == type) & date <= reproduce_at) %>%
    dplyr::group_by(hospital,study_year) %>%
    # given a particular hospital or study year combo find he most recent file
    stats::filter(date == suppressWarnings(max(date))) %>%
    dplyr::arrange(filetype) %>%
    stats::filter(dplyr::row_number() == suppressWarnings(max(dplyr::row_number()))) %>%
    # this will give us versioned and unversioned
    # is this file a single file on a particular date with no version, or a versioned set of files (originally this was trust specific but also happens when it is year specific?
    dplyr::mutate(
      byTrust = !is.na(hospital),
      byYear = !is.na(study_year)
    ) %>%
    # get the most recent file or set of files if it is versioned.
    dplyr::group_by(byTrust,byYear) %>%
    dplyr::mutate(latest_date = suppressWarnings(max(date))) %>% dplyr::ungroup() %>%
    stats::filter(latest_date == suppressWarnings(max(latest_date))) %>%
    dplyr::ungroup() %>%
    dplyr::select(-byTrust,-byYear)
}

# detecting errors when merging dataframes ----

# extract parse issues
.detect_parse_issues = function(listOfDf) {
  suppressWarnings(purrr::map(listOfDf, ~ tibble::problems(.x)))
}

# parse the list of dataframes for columns and emptiness
# (list(iris,mtcars)) %>% .detect_structure()
.detect_structure =  function(listOfDf) {
  purrr::map(listOfDf, ~ dplyr::inner_join(
    .x %>% lapply(class) %>% unlist() %>% tibble::enframe() %>% dplyr::rename(type = value),
    .x %>% lapply(function(c) all(is.na(c))) %>% unlist() %>% tibble::enframe() %>% dplyr::rename(empty = value),
    by = "name"
  ))
}

# figure out which columns are empty
# (list(iris,mtcars %>% dplyr::mutate(carb=NA))) %>% .detect_structure() %>% .detect_empty()
.detect_empty = function(structure) {
  structure %>% purrr::map(~ .x %>% stats::filter(empty) %>% dplyr::pull(name))
}

# (list(iris %>% dplyr::mutate(mpg="wrong type"),mtcars %>% dplyr::mutate(carb=NA))) %>% .detect_structure() %>% .detect_mismatch()
.detect_mismatch = function(structure) {
  data = tibble::tibble(index = 1:length(structure), structure = structure) %>% tidyr::unnest(structure)
  # majority = data %>% stats::filter(!empty) %>% dplyr::group_by(name,type) %>% dplyr::count() %>% dplyr::group_by(name) %>% stats::filter(n == n())
  minority = data %>%
    # ignore empty columns as they are generally incorrectly typed as a logical(NA)
    stats::filter(!empty) %>%
    dplyr::group_by(name,type) %>% dplyr::mutate(n=n()) %>%
    dplyr::group_by(name) %>% dplyr::mutate(N = n()) %>%
    # Check that there is only one type for each of the column names.
    stats::filter(n!=N)
  structure %>% purrr::map(~ .x %>% stats::filter(!empty) %>% dplyr::semi_join(minority, by=c("name","type")) %>% dplyr::pull(name))
}

#' A valid set of types of file that can be loaded by `load_data(...)`
#'
#' @return nothing.
#' @export
#'
#' @examples
#' valid_types()
valid_types = function() {
  t = all_files()
  cat("By exact match on file name:\n")
  cat(paste0(sort(unique(t$filename)),collapse = ", "))
  cat("\nOr by file category:\n")
  cat(paste0(sort(unique(t$directory)),collapse = ", "))
  cat("\n")
}

#' Load data and check structure
#'
#' Loads the AvonCap data from a set of files, which may optionally be qualified by site ('BRI' or 'NBT') and database year ('20-21','21-22','22-23', or 'y1', 'y2', 'y3')
#'
#'
#' @param type - see valid_types() for current list in input directory
#' @param reproduce_at - the date at which to cut off newer data files
#' @param merge - should multiple files be mreged into a single data frame if possible.
#'
#' @return either a list of dataframes or a single merged dataframe
#' @export
#'
#' @examples
#' load_data("nhs-extract")
load_data = function(type, reproduce_at = as.Date(getOption("reproduce.at",default = Sys.Date())), merge = TRUE) {
  if(reproduce_at != Sys.Date()) warning("REPRODUCING RESULTS FROM: ",reproduce_at, ", to disable this set options(reproduce.at=NULL)")
  tmp = type
  # decide whether files are trust by trust or a single combined file
  tmp_files = most_recent_files(type, reproduce_at)
  if(nrow(tmp_files) == 0) stop("No suitable files matching ",type,", before date: ",reproduce_at)
  tmp2 = ggrrr::cached({
    files = tmp_files %>% dplyr::pull(path)
    if (length(files)>1 & length(unique(tmp_files$date)) > 1) {
      warning("The most recent versions of the inputs have different effective dates: ",type," i.e. ", paste0(files,collapse = ";"))
      warning("This could mean the files are out of sync.")
    }

    # TODO: This is super slow because it checks all the data types of everything
    # on the larger dataset it throws parse errors because it cannot guess the correct type
    # There is an argument for reading it all in as text then analysing and checking the type when normalising.
    # This would need a rethink on the way in which structural issues are dealt with.

    data = tmp_files %>%
      dplyr::mutate(
        csv = purrr::map(path, ~ suppressWarnings(readr::read_csv(.x, na = c("","NA","Na","na","N/A","UNK"), show_col_types = FALSE))),
        entries = purrr::map_dbl(csv, ~ nrow(.))
      )
    data2 = data %>%
      dplyr::mutate(file = fs::path_file(path)) %>%
      dplyr::mutate(parse_issues = .detect_parse_issues(csv)) %>%
      # get rid of all parsing metadata
      dplyr::mutate(csv = purrr::map(csv, ~ tibble::as_tibble(.x))) %>%
      dplyr::mutate(structure = .detect_structure(csv)) %>%
      dplyr::mutate(empty = .detect_empty(structure)) %>%
      dplyr::mutate(mismatches = .detect_mismatch(structure)) %>%
      dplyr::select(-path,-filename)
    col_suppress = unique(c(unlist(data2$mismatches)))

    if(length(col_suppress) > 0) {
      warning("INCONSISTENT COLUMN(S) IN FILES: ",paste0(col_suppress,collapse=";"))
      warning("NOT MERGING FILES")
      merge = FALSE
    }

    if (nrow(dplyr::bind_rows(data2$parse_issues))>0) {
      message(nrow(dplyr::bind_rows(data2$parse_issues))," parse issues in raw files. Check the parse_issues attrbute.")
    }

    if (!merge) {
      return(data2 %>% dplyr::select(hospital,study_year,file,csv, entries, mismatches, empty, structure, parse_issues))
    }

    total = sum(data2$entries)

    tmp = data2 %>%
      # Lose empty columns which will have been assigned incorrect type
      dplyr::mutate(csv = purrr::map2(csv, empty, ~ .x %>% dplyr::select(-any_of(.y)))) %>%
      # Lose conflicting data type columns
      dplyr::mutate(csv = purrr::map2(csv, mismatches, ~ .x %>% dplyr::select(-any_of(.y)))) %>%
      # force merge the files together
      dplyr::select(hospital,study_year,file,csv) %>%
      tidyr::unnest(csv)

    message("Loaded ",nrow(tmp)," rows from ",nrow(data2)," files, (", paste0(data2$entries,collapse="+"),"=",total,")")
    if (nrow(tmp) != total) stop("The row numbers of the merged files", nrow(tmp)," do not add up to expected, ",total)

    attr(tmp,"parse_issues") = dplyr::bind_rows(data2$parse_issues)
    attr(tmp,"file") = paste0(fs::path_file(files), collapse="; ")
    attr(tmp,"date") = unique(tmp_files$latest_date)
    tmp
  },filename, reproduce_at, merge, tmp_files, .cache = input("cache"))
  return(tmp2)
}

#' Write file source information out to a text files
#'
#' @param rawDataDf The result of a `load_data(...)` call
#' @param out the `ggrrr::outputter`
#'
#' @return nothing
#' @export
save_data_source_info = function(rawDataDf, out) {
  readr::write_lines(x = c(
    attr(rawDataDf,"file"),
    digest::digest(rawDataDf, algo="md5")), file = out("data_sources.txt"))
}


## Data normalisation infrastructure ----


normalise_data = function(
    rawData,
    ethnicityFiles = most_recent_files("ethnicity",reproduce_at=Sys.Date()),
    remove_mapped = TRUE,
    remove_unmapped = TRUE,
    mappings=.mappings,
    messages = c("files: {files}","{.total} rows","analysis from: {reproduce_at}","files from: {date}"),
    reproduce_at = as.Date(getOption("reproduce.at",default = Sys.Date())),
    ...
) {

  reproduce_at = as.Date(getOption("reproduce.at",default = Sys.Date()))
  files = attr(rawData,"file")
  date = attr(rawData,"date")

  try({
    ethn = dplyr::bind_rows(lapply(ethnicityFiles$path, readr::read_csv))
    rawData = rawData %>% dplyr::left_join(ethn, by="record_number", suffix = c("",".ethn"))
  })

  ggrrr::cached({
    tmp = rawData
    if ("admission_date" %in% colnames(tmp)) {
      # the NHS data set has and admission date
      tmp = tmp %>%
        dplyr::mutate(
          year = lubridate::year(admission_date),
          week_number = lubridate::epiweek(admission_date),
          study_week = study_week(admission_date),
          study_year = year-2019+ifelse(week_number>30,0,1)
        )
    } else if (all(c("study_year","week_number") %in% colnames(tmp))) {
      tmp = tmp %>%
        # the Bristol data set has week_number which is a week number from start of the study in that year.
        # The study starts on week 31. Therefore for the 20-21 database (i.e. study_year 1) weeks 31-52 are in 2020 and 0-30 are in 2021
        # we get the year from the file-name itself (which assumes it was correctly named)
        dplyr::mutate(
          year = dplyr::case_when(
            is.numeric(year) & !is.na(year) ~ year,
            study_year == 1 & week_number>30 ~ 2020,
            study_year == 1 & week_number<=30 ~ 2021,
            study_year == 2 & week_number>30 ~ 2021,
            study_year == 2 & week_number<=30 ~ 2022,
            study_year == 3 & week_number>30 ~ 2022,
            study_year == 3 & week_number<=30 ~ 2023,
            study_year == 4 & week_number>30 ~ 2023,
            study_year == 4 & week_number<=30 ~ 2024,
            TRUE ~ NA_real_
          )) %>%
        dplyr::mutate(
          study_week = (year-2020)*52+week_number-1,
          admission_date = start_date_of_week(study_week)
          # week_number = lubridate::epiweek(admission_date)
        )
    }

    if (!"hospital" %in% colnames(tmp)) {
      # The hospital may be known from the file the data came from. If not we can work it out from
      # the record number
      tmp = tmp %>% dplyr::mutate(hospital = dplyr::case_when(
        tolower(substr(record_number,1,1)) == "b" ~ "BRI",
        tolower(substr(record_number,1,1)) == "n" ~ "NBT",
        TRUE ~ NA_character_
      ))
    }

    originalColnames = colnames(tmp)
    # prefix all the original columns with a single "."
    tmp = tmp %>% dplyr::rename_with(.fn= ~ paste0(".",.x))

    # mutate field values into new values
    for(i in 1:length(mappings)) {
      mappingName = names(mappings)[[i]]

      .fn = mappings[[i]]
      tomap = paste0(".",mappingName)
      if (tomap %in% colnames(tmp)) {
      # add in the "."
        tryCatch({
          tmp = tmp %>% .fn(paste0(".",mappingName))
        }, error = function(e) {
          warning("could not process column or column set ",mappingName," due to ",e$message)
        })
      } else {
        warning("the input data set does not have a ",mappingName," column")
      }

    }

    fileName = files

    message("mapped ",tmp %>% dplyr::select(testthat::starts_with("..")) %>% colnames() %>% length()," columns")
    if(remove_mapped) {
      tmp = tmp %>% dplyr::select(-testthat::starts_with(".."))
    } else {
      message("renamed original columns as: ",tmp %>% dplyr::select(testthat::starts_with("..")) %>% colnames() %>% paste0(collapse="; "))
    }

    unmappedCols = tmp %>% dplyr::select(c(testthat::starts_with("."), -testthat::starts_with(".."))) %>% colnames()

    message("Did not map ", unmappedCols %>% length()," columns")

    # detect multiple admission episodes based on nhs_number, if present
    tryCatch({
      tmp = tmp %>% dplyr::group_by(.nhs_number) %>% dplyr::arrange(admission.date) %>%
        dplyr::mutate(
          admission.episode = dplyr::row_number(),
          admission.interval = as.integer(admission.date-stats::lag(admission.date))
        ) %>% dplyr::ungroup()
    }, error = function(e) warning("could not identify duplicates by NHS number"))

    if (!"admission.episode" %in% colnames(tmp)) tmp = tmp %>% dplyr::mutate(admission.episode = NA_real_)

    if(remove_unmapped) {
      tmp = tmp %>% dplyr::select(!(c(testthat::starts_with("."), -testthat::starts_with(".."))))
    } else {
      message("renamed unmapped columns as: ",unmappedCols %>% paste0(collapse="; "))
    }

    tmp %>% dtrackr::track(.messages = messages) %>% dtrackr::capture_exclusions()

  }, rawData, mappings, remove_mapped, remove_unmapped, .cache = here::here("input/cache"), ...)
  # return(tmp2)
}

# Allows a
.normalise_variant = function(renameTo) {
  renameTo = rlang::ensym(renameTo)
  return(function(df, valueCol) {
    valueCol = as.symbol(valueCol)
    message("mapping ",valueCol," to ",renameTo)
    df %>% dplyr::mutate(!!renameTo := dplyr::case_when(
        !!valueCol %>% stringr::str_detect("(P|p).*(R|r)") ~ "Delta",
        !!valueCol %>% stringr::str_detect("(K|k).*(N|n)") ~ "Omicron",
        is.na(!!valueCol) ~ NA_character_,
        TRUE ~ "unknown"
      ) %>% factor(levels = c("unknown","Delta","Omicron"))) %>%
      dplyr::mutate(!!renameTo := !!renameTo %>% magrittr::set_attr("src",valueCol)) %>%
      dplyr::rename(rlang::!!(paste0(".",valueCol)) := (!!valueCol))
  })
}

# TODO: use labelled:: for column names

.normalise_list = function(renameTo, values, ordered = FALSE, zeroValue=FALSE, codes=(1:length(values))-zeroValue) {
  renameTo=rlang::ensym(renameTo)
  return(function(df, valueCol) {
    valueCol = as.symbol(valueCol)
    message("mapping ",valueCol," to ",renameTo)
    df %>%
      dplyr::mutate(!!renameTo := !!valueCol %>% factor(levels=codes, labels=values, ordered = ordered)) %>%
      dplyr::mutate(!!renameTo := !!renameTo %>% magrittr::set_attr("src",valueCol)) %>%
      dplyr::rename(rlang::!!(paste0(".",valueCol)) := (!!valueCol))
  })
}

.normalise_yesno = function(renameTo) {
  #TODO: error checking
  .normalise_list({{renameTo}}, c("no","yes"), zeroValue=TRUE)
}

.normalise_name = function(renameTo) {
  renameTo=rlang::ensym(renameTo)
  return(function(df, valueCol) {
    message("mapping ",valueCol," to ",renameTo)
    #TODO: error checking
    valueCol = as.symbol(valueCol)
    df %>%
      dplyr::mutate(!!renameTo := !!valueCol) %>%
      dplyr::mutate(!!renameTo := !!renameTo %>% magrittr::set_attr("src",valueCol)) %>%
      dplyr::rename(rlang::!!(paste0(".",valueCol)) := (!!valueCol))
  })
}

.normalise_double = function(renameTo, limits=c(-Inf,Inf)) {
  renameTo=rlang::ensym(renameTo)
  return(function(df, valueCol) {
    message("mapping ",valueCol," to ",renameTo)
    #TODO: error checking
    valueCol = as.symbol(valueCol)
    df %>%
      dplyr::mutate(!!renameTo :=  suppressWarnings(as.numeric(!!valueCol))) %>%
      dplyr::mutate(!!renameTo :=  dplyr::if_else(!!renameTo < limits[1] | !!renameTo > limits[2],NA_real_,!!renameTo)) %>%
      dplyr::mutate(!!renameTo := !!renameTo %>% magrittr::set_attr("src",valueCol)) %>%
      dplyr::rename(rlang::!!(paste0(".",valueCol)) := (!!valueCol))
  })
}

.normalise_text_to_factor = function(renameTo, levels) {
  renameTo=rlang::ensym(renameTo)
  return(function(df, valueCol) {
    message("mapping ",valueCol," to ",renameTo)
    #TODO: error checking
    valueCol = as.symbol(valueCol)
    df %>%
      dplyr::mutate(!!renameTo := suppressWarnings(factor(tolower(!!valueCol), levels=tolower(levels), labels=levels))) %>%
      dplyr::mutate(!!renameTo := !!renameTo %>% magrittr::set_attr("src",valueCol)) %>%
      dplyr::rename(rlang::!!(paste0(".",valueCol)) := (!!valueCol))
  })
}

.normalise_date = function(renameTo, limits=as.Date(c("2020-01-01","2030-01-01")), tryFormats="%d/%m/%Y") {
  renameTo=rlang::ensym(renameTo)
  return(function(df, valueCol) {
    message("mapping ",valueCol," to ",renameTo)
    #TODO: error checking
    valueCol = as.symbol(valueCol)
    df %>%
      dplyr::mutate(!!renameTo :=  suppressWarnings(as.Date(!!valueCol, tryFormats = tryFormats))) %>%
      dplyr::mutate(!!renameTo :=  dplyr::if_else(!!renameTo < limits[1] | !!renameTo > limits[2],as.Date(NA),!!renameTo)) %>%
      dplyr::mutate(!!renameTo := !!renameTo %>% magrittr::set_attr("src",valueCol)) %>%
      dplyr::rename(rlang::!!(paste0(".",valueCol)) := (!!valueCol))
  })
}

.normalise_checkboxes = function(renameToVars) {
  return(function(df, valueColPrefix) {

    i=1
    naCol = as.symbol(paste0(valueColPrefix,"___na"))
    hasNa = rlang::as_label(naCol) %in% colnames(df)
    for(renameTo in renameToVars) {
      # figure out the name in the data of the column
      valueCol = as.symbol(paste0(valueColPrefix,"___",i))
      message("mapping ",valueCol," to ",renameTo)
      # rename original ___1, ___2, etc to something meaningful and convert to ordered factor
      df = df %>% dplyr::mutate(!!renameTo := !!valueCol)
      if(hasNa) {
        # deal with ___na columns etc, by making the renamed checkbox variables have an NA in them for the values where NA has been checked
        df = df %>% dplyr::mutate(!!renameTo := dplyr::if_else(!!naCol == 1, NA_real_, !!renameTo))
      }
      df = df %>% dplyr::mutate(!!renameTo := !!renameTo %>% factor(levels=c(0,1), labels=c("no","yes")))
      # hide original ___1, ___2, etc columns
      df = df %>% dplyr::rename(rlang::!!(paste0(".",valueCol)) := (!!valueCol))
      #TODO: validation checking?
      i=i+1
    }
    # hide original ___na columns
    if(hasNa) df = df %>% dplyr::rename(rlang::!!(paste0(".",naCol)) := (!!naCol))

    df = df %>% dplyr::mutate(!!renameTo := !!renameTo %>% magrittr::set_attr("src",valueColPrefix))
    return(df)


  })
}

.normalise_checkboxes_to_list = function(renameTo, values, ordered = FALSE, zeroValue=FALSE, codes=(1:length(values))-zeroValue) {
  renameTo=rlang::ensym(renameTo)
  # return(function(df, valueCol) {
  #   valueCol = as.symbol(valueCol)
  #   message("mapping ",valueCol," to ",renameTo)
  #   df %>%
  #     dplyr::mutate(!!renameTo := !!valueCol %>% factor(levels=codes, labels=values, ordered = ordered)) %>%
  #     dplyr::rename(rlang::!!(paste0(".",valueCol)) := (!!valueCol))
  # })

  return(function(df, valueColPrefix) {

    naCol = as.symbol(paste0(valueColPrefix,"___na"))
    hasNa = rlang::as_label(naCol) %in% colnames(df)

    df = df %>% dplyr::mutate(!!renameTo := methods::as(NA,class(values)))

    for(i in 1:length(values)) {
      value = values[i]
      code = codes[i]
      # figure out the name in the data of the column
      valueCol = as.symbol(paste0(valueColPrefix,"___",code))
      message("mapping ",valueCol," to ",renameTo,", value ",value)
      df = df %>% dplyr::mutate(!!renameTo := ifelse(!!valueCol == 1 & is.na(!!renameTo),value,!!renameTo))
      # no need to deal with ___na columns etc as columns start with NA. no way to tell missing from present but NA.
      # hide original ___1, ___2, etc columns
      df = df %>% dplyr::rename(rlang::!!(paste0(".",valueCol)) := (!!valueCol))
      #TODO: validation checking?
    }

    # hide original ___na columns
    if(hasNa) df = df %>% dplyr::rename(rlang::!!(paste0(".",naCol)) := (!!naCol))
    df = df %>% dplyr::mutate(!!renameTo := !!renameTo %>% magrittr::set_attr("src",valueColPrefix))
    return(df)

  })
}

# lrtd_normalise = function(lrtd_data = load_data("AvonCAPLRTDCentralDa")) {
#   ethn = readr::read_csv(here::here("input/Ethnicity Data.csv"))
#   # With the data from bristol the year and
#   lrtd_data2 = lrtd_data %>% dplyr::left_join(ethn, by="record_number") %>%
#     # the years are sometimes missing when
#     dplyr::mutate(year = dplyr::case_when(
#       !is.na(year) ~ year,
#       year == "y1" & week_number>30 ~ 2020,
#       year == "y1" & week_number<=30 ~ 2021,
#       year == "y2" & week_number>30 ~ 2021,
#       year == "y2" & week_number<=30 ~ 2022,
#       year == "y3" & week_number>30 ~ 2022,
#       year == "y3" & week_number<=30 ~ 2023,
#       TRUE ~ NA_real_
#     )) %>%
#     dplyr::mutate(study_week = (year-2020)*52+week_number)
#   # These variables get picked up by the additional mappings in lrtd_mappings:
#   lrtd_norm = lrtd_data2 %>% normalise_data()
#
#   v = lrtd_norm %>% ggrrr::get_value_sets()
#
#   lrtd_norm = lrtd_norm %>% dplyr::mutate(
#     # this is a study specific variable.
#     admission.study_week_start_date = start_date_of_week(admission.study_week)
#   )
#
#   return(lrtd_norm)
# }

## Column naming ----

.column_names = list(
  demog.imd_decile = "IMD (decile)",
  genomic.variant_inferred = "Variant",
  admission.curb_65_severity_score = "CURB65 score",
  demog.age = "Age",
  admission.news2_score = "NEWS2 score",
  qcovid2.hazard_ratio = "QCovid2 HR",
  qcovid2.log_hazard = "QCovid2 log hazard",
  admission.charlson_comorbidity_index = "CCI",
  admission.cci_category = "CCI category",
  admission.covid_pcr_result = "PCR result",
  day_7.WHO_clinical_progression = "WHO Outcome score",
  day_7.max_o2_level = "Max FiO2",
  day_7.length_of_stay = "Length of Stay",
  demog.pcr_positive_by_age = "PCR positives (by age)",
  demog.age_eligible = "Age eligible for PneumoVax",
  admission.presentation_3_class = "aLTRD presentation"
)

# just a mapping function to get a readable label from the named variable.
# TODO: might be better to use the labelled package for this.
readable_label = function(columnVar, colNames = .column_names) {
  columnVar = rlang::ensym(columnVar)
  tmp = rlang::as_label(columnVar)
  if (!is.null(colNames[[tmp]])) {
    return(colNames[[tmp]])
  }
  tmp = tmp %>% stringr::str_remove("[a-zA-Z0-9_]+\\.") %>% stringr::str_replace_all("_"," ")
  if (tmp == toupper(tmp)) return(tmp)
  if (stringr::str_length(tmp)<=4) return(toupper(tmp))
  return(tmp %>% stringr::str_to_sentence())
}

#
readable_label_mapping = function(columnVars, colNames = .column_names) {
  tmp = unname(columnVars) %>% sapply(readable_label, colNames=colNames)
  if(is.list(columnVars)) {
    names(tmp) = unname(columnVars) %>% sapply(as_label)
  } else {
    names(tmp) = unname(columnVars)
  }
  return(tmp)
}

## Study dates and weeks ----

study_week = function(dates) {
  return(as.integer(as.Date(dates)-as.Date("2019-12-30")) %/% 7)
}

start_date_of_week = function(study_week) {
  return(as.Date("2019-12-30")+study_week*7)
}

## Exclusions ----

standard_exclusions = function(avoncap_df) {
  tmp3 = avoncap_df
  v = tmp3 %>% ggrrr::get_value_sets()
  reproduce_at = as.Date(getOption("reproduce.at",default = Sys.Date()))

  # Self documenting exclusions
  tmp3 = tmp3 %>%
    dtrackr::exclude_all(
      diagnosis.clinical_or_radiological_LRTI_or_pneumonia==v$diagnosis.clinical_or_radiological_LRTI_or_pneumonia$no & diagnosis.qualifying_symptoms_signs < 2 ~ "{.excluded} with fewer than 2 symptoms and not proven LRTI / pneumonia",
      demog.age<18 ~ "{.excluded} under 18 on admission",
      vaccination.first_dose_brand == v$vaccination.first_dose_brand$Pfizer & vaccination.first_dose_date < "2020-12-08" ~ "{.excluded} with first pfizer before 8/12/2020",
      vaccination.first_dose_brand == v$vaccination.first_dose_brand$AZ & vaccination.first_dose_date < "2021-01-04" ~ "{.excluded} with first AZ before 4/1/2021",
      admission.duration_symptoms > 10 ~ "{.excluded} symptomatic >10 days before admission",
      admission.date > reproduce_at-7 ~ "{.excluded} with admission after {format(reproduce_at-7, '%d/%m/%Y')}",
      admission.episode > 1 ~ "{.excluded} repeat admissions",
      .stage = "standard exclusions"
    )
  return(tmp3)
}




